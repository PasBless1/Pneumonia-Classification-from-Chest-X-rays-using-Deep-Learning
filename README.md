# Pneumonia-Classification-from-Chest-X-rays-using-Deep-Learning
Pneumonia remains a major global health burden, and chest X‑ray is the primary imaging modality for diagnosis in routine clinical workflows.
**1. Problem statement**

Pneumonia remains a major global health burden, and chest X‑ray is the primary imaging modality for diagnosis in routine clinical workflows. Early and reliable detection is critical, yet radiologist workloads are high and visual assessment is subject to inter‑reader variability. This project tackles a binary classification problem: given a frontal chest X‑ray, automatically predict whether the image shows radiological signs of pneumonia (positive) or not (negative). The goal is to build a reproducible deep learning pipeline that can serve as a baseline for decision support or as a starting point for more advanced computer‑aided diagnosis systems.

**2. Dataset and preprocessing**

The project uses the RSNA Pneumonia Detection Challenge dataset, which provides chest X‑ray images in DICOM format along with a CSV file that contains bounding box annotations and a binary target label per patient. Because multiple pneumonia regions can be annotated for the same exam, the raw labels may contain several rows per patient ID. For this classification task, the labels are simplified by dropping duplicate patient IDs and retaining a single binary “Target” value per image, reducing the detection problem to a clean image‑level classification setting.

After de‑duplication, the images are split into training and validation sets. The split preserves the natural class imbalance of the dataset, resulting in substantially more normal (no pneumonia) than pneumonia cases in both subsets. The preprocessing pipeline then converts each DICOM file into a normalized numpy array: pixel data are read using a medical imaging library, scaled by the global maximum intensity (255), and resized from the original resolution to 224×224 pixels to match the input size expected by standard convolutional neural networks. During this conversion pass, the pipeline accumulates the sum and squared sum of all pixel values to compute a global mean and standard deviation for the training set, which are later used for normalization inside the PyTorch data loaders.

To make training efficient and modular, the processed arrays are written to disk as .npy files using float16 precision, significantly reducing storage overhead while retaining sufficient numeric fidelity. The files are organized into a directory structure compatible with torchvision’s DatasetFolder interface: separate train and val folders each contain two subdirectories, 0 for normal X‑rays and 1 for pneumonia X‑rays. This design keeps the data loader implementation simple, supports easy extension with data augmentation, and allows the preprocessing step to be run once and reused across multiple training experiments.

**3. Model architecture and training strategy**

The classifier is built on top of a ResNet‑18 backbone implemented in PyTorch and wrapped in a PyTorch Lightning module for clean, modular training logic. Since chest X‑ray images are single‑channel, the first convolutional layer of the standard ResNet‑18 is replaced with a 1‑channel convolution (kernel size 7, stride 2, padding 3), while the rest of the backbone remains unchanged. The final fully connected layer is modified from a multi‑class output to a single neuron with linear activation, producing one logit that represents the pneumonia probability after a sigmoid transformation.

For optimization, the project uses the binary cross‑entropy loss with logits (BCEWithLogitsLoss). The loss function can be configured with a positive class weight (pos_weight) to partially compensate for the imbalance between normal and pneumonia examples, as pneumonia cases are under‑represented in the dataset. The model parameters are updated with the Adam optimizer using a learning rate of 1e‑4, which offers a good balance between stability and convergence speed for this architecture and dataset size. Accuracy is tracked as the primary performance metric using the torchmetrics library, and separate training and validation metrics are logged at the end of each epoch.

Training is orchestrated with PyTorch Lightning, which encapsulates the forward pass, loss computation, optimization step, and validation loop in a single LightningModule. A trainer object handles device placement, logging, and checkpointing, saving the best-performing model weights based on validation performance. The data loaders feed batched, normalized numpy arrays directly to the model, allowing efficient GPU training. This setup makes it straightforward to experiment with alternative backbones, learning rates, or augmentation strategies without changing the surrounding training infrastructure.

**4. Implementation and interpretability**

The implementation is organized as a self‑contained notebook that covers the complete workflow: downloading the RSNA dataset, converting DICOM images into numpy arrays, setting up PyTorch data modules, defining the model, and running training and evaluation. The PneumoniaModel Lightning class encapsulates the network architecture, loss function, optimizer configuration, and training/validation steps, keeping the high‑level training script concise and readable. An additional inference section loads the best checkpoint and runs the model on the validation set to generate probability scores and class predictions for each image.

Beyond raw accuracy, the project emphasizes interpretability and practical evaluation. The model’s logits are passed through a sigmoid to obtain probabilities for the pneumonia class, and a default decision threshold of 0.5 is used to convert probabilities into binary labels. The notebook computes standard classification metrics such as accuracy, precision, recall, and confusion matrices, which provide insight into how the model behaves on normal versus pneumonia cases. To explore clinical trade‑offs, the decision threshold is varied (for example, to 0.25), showing how lowering the threshold increases sensitivity (fewer missed pneumonia cases) at the expense of more false positives. Although the current version focuses on metric‑level interpretability, the architecture and code structure are ready to be extended with techniques such as Grad‑CAM or other saliency methods to visualize which regions of the X‑ray drive the model’s decisions.

**5. Results and key insights**
   
On the held‑out validation set, the ResNet‑18‑based classifier achieves robust performance despite the inherent class imbalance in the RSNA dataset. With a decision threshold of 0.5, the model reaches validation accuracy in the mid‑80% range and shows a reasonable balance between precision and recall: it correctly identifies a large fraction of normal exams while still detecting most pneumonia cases. The confusion matrix at this threshold confirms that false negatives (missed pneumonia) are present but kept at a moderate level, which is important in safety‑critical medical contexts.

When the decision threshold is lowered to 0.25, the model becomes more sensitive to pneumonia, substantially reducing the number of false negatives but increasing the number of false positives. This behavior is consistent with the typical precision–recall trade‑off in binary classification, especially in imbalanced medical datasets. From a deployment perspective, the results suggest that the model is well suited as a triage or second‑reader tool: it can flag suspicious exams for closer review while allowing clinicians to tune the operating threshold according to their tolerance for missed cases versus over‑calling pneumonia. Overall, the project demonstrates that a relatively lightweight convolutional architecture, paired with careful preprocessing and training, can provide a strong and extensible baseline for automated pneumonia detection from chest X‑rays.
